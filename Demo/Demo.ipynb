{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DZsJnrjR0qf"
      },
      "source": [
        "# RNN Manual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwi-d9C6R_53",
        "outputId": "2d39a7c9-d263-4e61-e321-29b312760df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W_xh shape: torch.Size([2, 5])\n",
            "W_hh shape: torch.Size([2, 2])\n",
            "b_xh shape: torch.Size([2])\n",
            "b_hh shape: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(1)\n",
        "\n",
        "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True)\n",
        "\n",
        "w_xh = rnn_layer.weight_ih_l0\n",
        "w_hh = rnn_layer.weight_hh_l0\n",
        "b_xh = rnn_layer.bias_ih_l0\n",
        "b_hh = rnn_layer.bias_hh_l0\n",
        "\n",
        "print('W_xh shape:', w_xh.shape)\n",
        "print('W_hh shape:', w_hh.shape)\n",
        "print('b_xh shape:', b_xh.shape)\n",
        "print('b_hh shape:', b_hh.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF0Uf3aLVj5S",
        "outputId": "464beb5f-e6ca-4c81-a3ed-5bb94053c00d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121, -0.1371,  0.3319, -0.6657],\n",
            "        [ 0.4241, -0.1455,  0.3597,  0.0983, -0.0866]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.1961,  0.0349],\n",
            "        [ 0.2583, -0.2756]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0516, -0.0637], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1025, -0.0028], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(w_xh)\n",
        "print(w_hh)\n",
        "print(b_xh)\n",
        "print(b_hh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDh34cOmV-5S",
        "outputId": "e16882af-e23e-4695-bce8-6acaf1a6601d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3.]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
        "x_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1OnR0rzWSb6",
        "outputId": "1c57da47-8b42-4b76-8175-aa1f82ebb7ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3520,  0.5253],\n",
            "         [-0.6842,  0.7607],\n",
            "         [-0.8649,  0.9047]]], grad_fn=<TransposeBackward1>)\n",
            "tensor([[[-0.8649,  0.9047]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "## output of the simple RNN:\n",
        "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
        "print(output)\n",
        "print(hn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ZcXChuc-Vu",
        "outputId": "b3f0804a-3b76-404b-8c32-6c65bb3de654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time step 0 =>\n",
            "   Input           : [[1. 1. 1. 1. 1.]]\n",
            "   Hidden          : [[-0.4701929   0.58639044]]\n",
            "   Output (manual) : [[-0.3519801   0.52525216]]\n",
            "   RNN output      : [[-0.3519801   0.52525216]]\n",
            "\n",
            "Time step 1 =>\n",
            "   Input           : [[2. 2. 2. 2. 2.]]\n",
            "   Hidden          : [[-0.88883156  1.2364398 ]]\n",
            "   Output (manual) : [[-0.68424344  0.76074266]]\n",
            "   RNN output      : [[-0.68424344  0.76074266]]\n",
            "\n",
            "Time step 2 =>\n",
            "   Input           : [[3. 3. 3. 3. 3.]]\n",
            "   Hidden          : [[-1.3074702  1.8864892]]\n",
            "   Output (manual) : [[-0.8649416  0.9046636]]\n",
            "   RNN output      : [[-0.8649416  0.9046636]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "out_man = []\n",
        "\n",
        "for t in range(3):\n",
        "    zt = torch.reshape(x_seq[t], (1, 5))\n",
        "    print(f'Time step {t} =>')\n",
        "    print('   Input           :', zt.numpy())\n",
        "\n",
        "    ht = torch.matmul(zt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
        "    print('   Hidden          :', ht.detach().numpy())\n",
        "\n",
        "    if t>0:\n",
        "        prev_h = out_man[t-1]\n",
        "    else:\n",
        "        prev_h = torch.zeros((ht.shape))\n",
        "\n",
        "    yt = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
        "    yt = torch.tanh(yt)\n",
        "    out_man.append(yt)\n",
        "    print('   Output (manual) :', yt.detach().numpy())\n",
        "    print('   RNN output      :', output[:, t].detach().numpy())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QXtWZIbOgzL"
      },
      "source": [
        "# Predicting the sentiment of IMDb movie reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUc9Q0YSOmMZ"
      },
      "source": [
        "### Preparing the movie review data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmz5yURuTnx9",
        "outputId": "2d957df5-20e3-4dbf-8f82-6c40459d8142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.16.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Collecting torch==2.1.2 (from torchtext)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Collecting torchdata==0.7.1 (from torchtext)\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchtext)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->torchtext) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.7.0\n",
            "    Uninstalling torchdata-0.7.0:\n",
            "      Successfully uninstalled torchdata-0.7.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 torchdata-0.7.1 torchtext-0.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjF3kv3KUg4L",
        "outputId": "c43ff79d-3d02-4bed-a6db-072e8203db05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata) (12.3.101)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torchdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmkBqnZT59j",
        "outputId": "e4eab51a-def4-45a2-c751-f0f55d5f8d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp-hS-TdO5ul"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.datasets import IMDB\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxDaxyDZPUl9"
      },
      "outputs": [],
      "source": [
        "# Step 1: load and create the datasets\n",
        "\n",
        "train_dataset = IMDB(split='train')\n",
        "test_dataset = IMDB(split='test')\n",
        "\n",
        "test_dataset = list(test_dataset)\n",
        "torch.manual_seed(1)\n",
        "train_dataset, valid_dataset = random_split(\n",
        "    list(train_dataset), [20000, 5000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XWezt32Qlfb",
        "outputId": "74717d3a-32be-4689-c532-95ee350f0424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab-size: 69023\n"
          ]
        }
      ],
      "source": [
        "## Step 2: find unique tokens (words)\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "token_counts = Counter()\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
        "        ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = text.split()\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "for label, line in train_dataset:\n",
        "    tokens = tokenizer(line)\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "\n",
        "print('Vocab-size:', len(token_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fOaBmaaVNkI",
        "outputId": "9cf6f0da-86b0-42fb-b9bf-a4c922a21f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11, 7, 35, 457]\n"
          ]
        }
      ],
      "source": [
        "## Step 3: encoding each unique token into integers\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "vocab = vocab(ordered_dict)\n",
        "\n",
        "vocab.insert_token(\"<pad>\", 0)\n",
        "vocab.insert_token(\"<unk>\", 1)\n",
        "vocab.set_default_index(1)\n",
        "\n",
        "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndYn3CvHVXcT"
      },
      "outputs": [],
      "source": [
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: this code may be very slow on CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkIRYzDiVrBK"
      },
      "outputs": [],
      "source": [
        "## Step 3-A: define the functions for transformation\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "\n",
        "from torchtext import __version__ as torchtext_version\n",
        "from pkg_resources import parse_version\n",
        "\n",
        "label_pipeline = lambda x: 1. if x == 2 else 0.         # 1 ~ negative, 2 ~ positive review\n",
        "\n",
        "\n",
        "\n",
        "## Step 3-B: wrap the encode and transformation function\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text),\n",
        "                                      dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
        "        text_list, batch_first=True)\n",
        "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mDPHey5Vrw4",
        "outputId": "e4b02172-8f23-4e7c-b27e-c7e4fa3de377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
            "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
            "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
            "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
            "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
            "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
            "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
            "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
            "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
            "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
            "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
            "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
            "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
            "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
            "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
            "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
            "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
            "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
            "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
            "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
            "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
            "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
            "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
            "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
            "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
            "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
            "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
            "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
            "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
            "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
            "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
            "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
            "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
            "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
            "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
            "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
            "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
            "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
            "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
            "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
            "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
            "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
            "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
            "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
            "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
            "            24,   887,    32,    31,    19,     8,    13,   428],\n",
            "        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
            "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
            "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
            "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
            "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
            "         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
            "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
            "         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
            "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
            "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
            "           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
            "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
            "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
            "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
            "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
            "       device='cuda:0')\n",
            "tensor([1., 1., 1., 0.], device='cuda:0')\n",
            "tensor([165,  86, 218, 145], device='cuda:0')\n",
            "torch.Size([4, 218])\n"
          ]
        }
      ],
      "source": [
        "## Take a small batch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
        "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
        "print(text_batch)\n",
        "print(label_batch)\n",
        "print(length_batch)\n",
        "print(text_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BeOEmR5YRr0"
      },
      "outputs": [],
      "source": [
        "## Step 4: batching the datasets\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, collate_fn=collate_batch)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                      shuffle=False, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uDZbwS6Yhze",
        "outputId": "58722fb5-e8e8-4ad7-f4a4-f98d30d14e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.7039, -0.8321, -0.4651],\n",
            "         [-0.3203,  2.2408,  0.5566],\n",
            "         [-0.4643,  0.3046,  0.7046],\n",
            "         [-0.7106, -0.2959,  0.8356]],\n",
            "\n",
            "        [[-0.4643,  0.3046,  0.7046],\n",
            "         [ 0.0946, -0.3531,  0.9124],\n",
            "         [-0.3203,  2.2408,  0.5566],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "embedding = nn.Embedding(num_embeddings=10,\n",
        "                         embedding_dim=3,\n",
        "                         padding_idx=0)\n",
        "\n",
        "# a batch of 2 samples of 4 indices each\n",
        "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
        "print(embedding(text_encoded_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMXkgDJTYef5"
      },
      "source": [
        "### Bulding an RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89AQon7JjSqO"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, rnn_hidden_size, batch_first=True)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
        "        out, hidden = self.rnn(out)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z46jaBFAxKrO"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model_RNN = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F4R4g7Wb2MP"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model):\n",
        "    model.train()\n",
        "    total_acc, total_loss = 0, 0\n",
        "\n",
        "    for step, (text_batch, label_batch, lengths) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(text_batch, lengths)[:, 0]\n",
        "        loss = loss_fn(pred, label_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
        "        total_loss += loss.item() * label_batch.size(0)\n",
        "\n",
        "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)\n",
        "\n",
        "def evaluate(dataloader, model):\n",
        "    model.eval()\n",
        "    total_acc, total_loss = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (text_batch, label_batch, lengths) in enumerate(dataloader):\n",
        "            pred = model(text_batch, lengths)[:, 0]\n",
        "            loss = loss_fn(pred, label_batch)\n",
        "            total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
        "            total_loss += loss.item() * label_batch.size(0)\n",
        "\n",
        "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq80RHQUxySP"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZxOG8SMeQ4g",
        "outputId": "fc205438-41ac-496f-b726-d9bdc1f0838b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: RNN\n",
            "\n",
            "Epoch 0 accuracy: 0.5474 val_accuracy: 0.5472\n",
            "Epoch 1 accuracy: 0.6202 val_accuracy: 0.6494\n",
            "Epoch 2 accuracy: 0.6899 val_accuracy: 0.6774\n",
            "Epoch 3 accuracy: 0.7341 val_accuracy: 0.6972\n",
            "Epoch 4 accuracy: 0.7663 val_accuracy: 0.7020\n",
            "Epoch 5 accuracy: 0.7675 val_accuracy: 0.7312\n",
            "Epoch 6 accuracy: 0.7116 val_accuracy: 0.6590\n",
            "Epoch 7 accuracy: 0.8052 val_accuracy: 0.7224\n",
            "Epoch 8 accuracy: 0.7193 val_accuracy: 0.6712\n",
            "Epoch 9 accuracy: 0.7957 val_accuracy: 0.7636\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "num_epochs = 10\n",
        "torch.manual_seed(1)\n",
        "models = [model_RNN]\n",
        "models_name = ['RNN']\n",
        "for i, model in enumerate(models):\n",
        "  print(f\"Model name: {models_name[i]}\\n\" )\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  for epoch in range(num_epochs):\n",
        "      acc_train, loss_train = train(train_dl, model)\n",
        "      acc_valid, loss_valid = evaluate(valid_dl, model)\n",
        "      print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
